---
title: "Atelier 4: Mod√®les lin√©aires"
subtitle: "S√©rie d'ateliers R du CSBQ"
author: "Centre de la Science de la Biodiversit√© du Qu√©bec"
output:
  xaringan::moon_reader:
    includes:
      in_header: qcbsR-header.html
    lib_dir: assets
    seal: true
    css: ["default", "qcbsR.css", "qcbsR-fonts.css"]
    nature:
      beforeInit: "qcbsR-macros.js"

---

```{r setup, echo = FALSE}
knitr::opts_chunk$set(
  comment = "#",
  collapse = TRUE,
  #cache = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width=6, fig.height=6,
  fig.retina = 3,
  fig.align = 'center'
)
options(repos=structure(c(CRAN="http://cran.r-project.org")))
```

class: inverse, center, middle

```{R install_pkgs, echo = FALSE, results = "asis"}
cat(
  qcbsRworkshops::first_slides(4, c('dplyr', 'vegan', 'e1071', 'MASS', 'car','effect'), lang = "fr")
)
```

---

# Objectifs d'apprentissage

### Faire un t-test avec R

### Utiliser `lm()` pour faire un mod√®le lin√©aire avec R

### Utiliser `anova()` pour r√©aliser une analyse de variance avec R

---

class: inverse, center, middle

# Concepts importants

## D√©finir la moyenne et la variation

---
# Moyenne

La moyenne est une mesure de la valeur moyenne d'une population (*x*):

$$\bar{x} = \frac{1}{N} \sum_{i=1}^{n} x_{i}$$

.alert[Les notations math√©mathiques sont diff√©rentes des notations utilis√©es dans R .] 

.comment[Par  exemple, en math√©matique, *x* repr√©sente la population √† l'√©tude. Dans R, *X* repr√©sente habituellement un objec en utilisation au sein d'une fonction, ou fait r√©f√©rence √† un axe d'un graphique. Faites attention de bein comprendre la notation utilis√©e lorsque vous roulez une fonction.]

---
# Variation

- La variation est la dispersion des observations autour de la moyenne
  - √âcart moyen
  - Variance
  - √âcart type
  - Coefficient de variation

**Mais qu'est-ce que c'est l'√©cart ?**

$$D_{i} = |x_{i} - \bar{x}|$$

---
# Variation

**L'√©cart**:

$$D_{i} = |x_{i} - \bar{x}|$$
--
**L'√©cart moyen**:

$$D = \frac{1}{n} \sum_{i=1}^{n} |x_{i} - \bar{x}|$$
--

Au lieu de valeurs absolues, nous pouvons √©galement mettre la valeur au carr√©, donnant la **variance**:

$$V = \frac{1}{n} \sum_{i=1}^{n} {(x_{i} - \bar{x})}^2$$

---
# Variation

Mais en mettant chaque valeur au carr√©, ces variables ne sont plus en unit√©s significatives

On fait donc la racine carr√©e de la **variance** ( $V$ ), donnant l'**√©cart type**:

$$\sigma = \sqrt{V}$$
--

L'√©cart type relatif, en pourcentage, est le **coefficient de variation**:

$$cv = \frac{\sigma}{\bar{x}}$$

---
class: inverse, center, middle

# Les mod√®les lin√©aires

---
# Les mod√®les lin√©aires

Relation lin√©aire entre une variable r√©ponse ( $Y$ ) et une/des explicative ( $X$ ), en utilisant les concepts de **moyenne** et **variance**

- $Y$ : variable que vous voulez expliquer (une seule variable r√©ponse)
- $X$ : variable pour expliquer variable r√©ponse (une ou plusieurs variables explicatives)
- $Y$ : doit √™tre quantitative
- $X$ : quantitative ou qualitative
- $\epsilon$ : ce qui n'est pas expliqu√© par la ou les variables explicatives ![:faic](arrow-right) r√©sidus ou erreur

---
# D√©finir des mod√®les lin√©aires

Rassembler tous ensemble :

$$Y_{i} = \beta_{0} + \beta_{1} x_{i1} + \cdots + \beta_{p} x_{ip} + \epsilon_{i}$$

- $Y_i$ est la variable r√©ponse
- $Œ≤_0$ est l'ordonn√©e √† l'origine de la droite de r√©gression
- $Œ≤_1$est le coefficient de variation de la $1^{√®re}$ variable explicative
- $Œ≤_p$ est le coefficient de variation de la $p^{√®me}$ variable explicative
- $x_{i1}$ est la variable explicative pour la $1^{√®re}$ observation
- $x_{ip}$ est la variable explicative pour la $p^{√®me}$ observation
- $Œµ_i$ sont les r√©sidus du mod√®le (i.e. la variance inexpliqu√©e)

---
# Le but des mod√®les lin√©aires

- Le but d'un mod√®le lin√©aire est de trouver la meilleure estimation des param√®tres (les variables $\beta$), puis d'√©valuer la qualit√© de l'ajustement du mod√®le

- Plusieurs m√©thodes ont √©t√© d√©velopp√©es pour calculer l'intercept et les coefficients de mod√®les lin√©aires
  -  Le choix appropri√© d√©pend du type de variables explicatives consid√©r√©es et de leur nombre

.center[.large[Le concept g√©n√©ral de ces m√©thodes consiste √† minimiser les r√©sidus]]

---
# Objectif d'enseignement

.center[
![:scale 100%](images/schema.png)
]

---
# Conditions de base du mod√®le lin√©aire

1. Les r√©sidus sont ind√©pendants
2. Les r√©sidus suivent une distribution normale
3. Les r√©sidus ont une moyenne de 0
4. Les r√©sidus sont homosc√©dastiques (i.e. leur variance est constante)

.alert[Ces 4 conditions concernent les r√©sidus, et non les variables r√©ponses ou explicatives]

.comment[Dans les sections suivantes, nous ne r√©p√©tons pas les conditions ci-dessus pour chaque mod√®le parce que ces conditions de base s'appliquent √† tous les mod√®les lin√©aires]

---
# Flux de travail

.center[
![:scale 62%](images/schema.png)
]

- Visualiser les donn√©es
- Cr√©er un mod√®le
- Tester les 4 conditions de base du mod√®le
- Ajuster le mod√®le si les conditions de base ne sont pas respect√©es
- Interpr√©ter les r√©sultats du mod√®le

---
class: inverse, center, middle

# R√©gression lin√©aire simple

---
# R√©gression lin√©aire simple

- Type de mod√®le lin√©aire qui contient seulement une variable explicative continue

$$Y_i = \beta_0 + \beta_1 x_i + \epsilon_i$$

- Estimation de l'**ordonn√©e √† l'origine** ( $\beta_0$ ) et d'un **coefficient de corr√©lation** ( $\beta_1$ )

- M√©thode des moindres carr√©s
  - m√©thode la plus couramment utilis√©e (d√©faut sur R)

---
# M√©thode des moindres carr√©s

Cette m√©thode assume que chaque point proviennent d'une distribution normale, la moyenne de cette distribution √©tant la relation lin√©aire.

.pull-left[
.center[![:scale 80%](images/graph_lm.png)]
]

.pull-right[
**Suppositions**

- $Y_i$ : valeur observ√©e (mesur√©e) pour $X_i$
- $\widehat{Y}_i$ : valeur pr√©dite pour $X_i$
- $\bar{Y}$ : moyenne de tout les $Y_i$
- $V_E$ : r√©sidus (erreur)
- $V_R$ : variance expliqu√©e par la r√©gression
- $V_T$ : variance totale
- $R^2 = \frac{V_R}{V_T}$
]

---
# Effectuer un mod√®le lin√©aire

.small[
**√âtape 1**. Ex√©cuter votre mod√®le lin√©aire

**√âtape 2**. V√©rifier les conditions d'application
]

<br>

.pull-left[.center[![:faic](arrow-down)]] .pull-right[.center[![:faic](arrow-down)]]

.pull-left[.center[*Conditions sont satisfaites ?*]

.small[**√âtape 3**. Estimer les param√®tres de r√©gression, test de signification, tracer votre mod√®le
]]

.pull-right[.center[*Conditions non satisfaites ?*]

.small[*Pouvez-vous transformer vos variables (est-ce justifi√©) ?*]

.pull-left[.center[![:faic](arrow-down)]] .pull-right[.center[![:faic](arrow-down)]]

.small[
.pull-left[
Oui: retourner √† l'√©tape 1 avec des variables transform√©es
]

.pull-right[
Non: essayer GLM qui pourrait mieux convenir aux donn√©es
]]]

---
# Ex√©cution du mod√®le lin√©aire dans R

**√âtape 1**. cr√©er votre mod√®le lin√©aire

Dans R, la fonction `lm()` est utilis√©e pour ajuster un mod√®le lin√©aire

```{r, eval = FALSE}
lm1 <- lm(Y~X)
```

- `lm1` : Nouvel objet contenant le mod√®le lin√©aire
- `Y` : Variable r√©ponse
- `X` : Variable ind√©pendante

---
# Ex√©cution du mod√®le lin√©aire dans R

T√©l√©charger les don√©es <span style="color:blue"> *birdsdiet* </span>:

```{r, eval = TRUE, echo = FALSE}
bird <- read.csv("data/birdsdiet.csv", stringsAsFactors = TRUE)
```

```{r, eval = FALSE}
bird <- read.csv("birdsdiet.csv", stringsAsFactors = TRUE)
```

Visualisez le tableau de la structure des donn√©es en utilisant la fonction `str()` :

```{r}
str(bird)
```

---
# Ex√©cution du mod√®le lin√©aire dans R

Variable r√©ponse : **abondance d'oiseaux**  ![:faic](arrow-right) num : quantitative

Variable explicative : **masse**   ![:faic](arrow-right)  num : quantitative

```{r}
str(bird)
```

Nous voulons d'abord v√©rifier si l'abondance maximale des oiseaux (`maxAbund`) est une fonction de la masse des oiseaux (`Mass`)

```{r eval=TRUE}
lm1 <- lm(MaxAbund ~ Mass, data = bird)
```

---
# Ex√©cution du mod√®le lin√©aire dans R

**√âtape 2**. V√©rifier les conditions d'application avec les graphiques diagnostics

```{r, eval=FALSE}
opar <- par(mfrow=c(2,2))
plot(lm1)
```

- `par( )`: d√©finit les param√®tres du graphique, par exemple, l'argument `mfrow` sp√©cifie le nombre de rang√©es et colonnes
- `plot( )`: est la fonction pour faire le graphique

La sortie comprend les quatre graphiques diagnostics de la fonction `lm()`

---
# Graph. #1 - R√©sidus vs valeurs pr√©dites

Exemple d'ind√©pendance .comment[(ce que nous recherchons !)]

- Devrait montrer une dispersion de points sans patron

```{r, echo = FALSE, fig.height=5.5, fig.width=6.5}
  set.seed(1234564)
  x <- abs(rnorm(100,10,10))
  y <- 2*x+0 + rnorm(100)
  lm <- lm(y~x)
  plot(lm, which = 1)
```

---
# Graph. #1 - R√©sidus vs valeurs pr√©dites

Example de non-ind√©pendance .comment[(ce que nous ne voulons pas !)]
```{r, echo=FALSE, fig.height=4.5, fig.width=8.5, warning=FALSE}
par(mfrow=c(1,2))
set.seed(1234564)
x = abs(rnorm(100,10,10))
y = (x)^2 + rnorm(length(x),0,30)
lm=lm(y~scale(x))
plot(lm,which = 1, main = "Non-lin√©aire", col.main="red")

x = abs(rnorm(100,10,10))
y = (x) + rnorm(length(x), 0, x)
lm=lm(y~scale(x))
plot(lm,which = 1, main = "H√©t√©rosc√©dastique", col.main="red")
```


- Solution: Transformer vos donn√©es ou essayer une distribution autre que lin√©aire (gaussienne); mod√®le lin√©aire g√©n√©ralis√© (GLM) (ex: Poisson, binomial, binomial n√©gatif, etc.)

---
# Graph. #2 - √©chelle localit√©

Devrait montrer une dispersion de points sans patron

```{r, echo=FALSE, fig.height=4.5, fig.width=9, warning=FALSE}
par(mfrow=c(1,2))
set.seed(1234564)
x <- 1:100
y <- x + rnorm(100,sd=5)
lm=lm(y~x)
plot(lm,which = 3)

set.seed(2)
x = abs(rnorm(100,10,10))
y = (x) + rnorm(length(x), 0, x)
lm=lm(y~scale(x))
plot(lm,which = 3)
```
.pull-left[.center[![:faic](arrow-up)]] .pull-right[.center[![:faic](arrow-up)]]

.pull-left[.center[Aucun patron dans les r√©sidus]] .pull-right[.center[Forte tendance dans les r√©sidus]]

---
# Graph. # 3 - Normal QQ

- Compare la distribution (quantiles) des r√©sidus aux quantiles d'une distribution normale
- Si les points se situent de fa√ßon lin√©aire sur la ligne 1: 1, les r√©sidus suivent une distribution normale

```{r, echo=FALSE, fig.height=4, fig.width=9, warning=FALSE}
par(mfrow=c(1,2), mar = c(4, 4, 1.5, 3))
set.seed(1234564)
x <- 1:100
y <- x + rnorm(100,sd=5)
lm=lm(y~x)
plot(lm, which = 2)

set.seed(2)
x = abs(rnorm(100,10,10))
y = (x) + 0 + rnorm(length(x), 0, x)
lm=lm(y~scale(x))
plot(lm, which = 2)
```

.pull-left[.center[![:faic](arrow-up)]] .pull-right[.center[![:faic](arrow-up)]]

.pull-left[.center[C'est bien !]] .pull-right[.center[Pas tr√®s bien...]]

---
# Graph. # 4 - R√©sidus vs effet de levier

- Recherche les valeurs influentes
- **Points de levier** : observations extr√™mes ou p√©riph√©riques de la variable explicative. Parce qu'ils n'ont pas d'observations voisines, la ligne de r√©gression passe pr√®s de ces points. **Ils peuvent (ou pas) avoir une grande influence sur la r√©gression**
- Les points de levier avec une forte influence peuvent √™tre identifi√©s avec une **distance de Cook sup√©rieure √† 0,5**

---
# Effet levier vs influence

```{r, echo=FALSE, fig.height=8, fig.width=7.7, warning=FALSE}
par(mfrow=c(3, 1), mar = c(4, 15, 1, 3), cex = 1.2)
set.seed(1234564)
x <- 1:20
y <- rnorm(x, x, 2)
lm0 <- lm(y ~ x)
# plot 1
plot(x, y, ylim = c(-4, 22), xlab = '', ylab = ''); abline(lm0, col = 2); points(11, -3, pch = 15)
# add 20, 10 point to the new lm
xx <- c(x, 11); yy <- c(y, -3)
abline(lm(yy ~ xx), col = 2, lty = 3)
text(-20, 10, srt=0, adj = 0, labels = "* Pas d'effet de levier \n* Faible influence
", xpd = TRUE, cex = 1.5)
# plot 2
plot(x, y, ylim = c(-4, 32), xlim = c(0, 31), xlab = '', ylab = ''); abline(lm0, col = 2); points(30, 30, pch = 15)
# add 20, 10 point to the new lm
xx <- c(x, 30); yy <- c(y, 30)
abline(lm(yy ~ xx), col = 2, lty = 3)
text(-33, 15, srt=0, adj = 0, labels = "* Effet de levier \n* Pas d'influence", xpd = TRUE, cex = 1.5)

# plot 3
plot(x, y, ylim = c(-4, 32), xlim = c(0, 31), xlab = '', ylab = ''); abline(lm0, col = 2); points(30, 15, pch = 15)
# add 20, 10 point to the new lm
xx <- c(x, 30); yy <- c(y, 15)
abline(lm(yy ~ xx), col = 2, lty = 3)
text(-33, 15, srt=0, adj = 0, labels = '* Effet de levier \n* Influence √©lev√©e', xpd = TRUE, cex = 1.5)
```

---
# Effet levier vs influence

```{r, echo=FALSE, fig.height=3.5, fig.width=9, warning=FALSE}
par(mfrow=c(1,2), mar = c(4, 4, 1.5, 3))
set.seed(1234564)
x <- 1:100
y <- x + rnorm(100,sd=5)
lm=lm(y~x)
plot(lm, which = 5)

set.seed(1234564)
x = abs(rnorm(100,10,10))
y = (x) + 0 + rnorm(length(x), 0, x)
lm=lm(y~scale(x))
plot(lm, which = 5)
```

.pull-left[.center[![:faic](arrow-up)]] .pull-right[.center[![:faic](arrow-up)]]

.pull-left[.center[Aucune valeur influente]]
.pull-right[.center[Effet de levier √©lev√© et influence raisonnable]]

<br />
<br />
<br />

.comment[Ici, le point 29 a un effet de levier √©lev√©, mais son influence est acceptable (√† l'int√©rieur des limites de la distance Cook de 0,5)]

---
# Effet levier vs influence

Effet de levier et influence √©lev√©e

<br />

.pull-left[
```{r, echo=FALSE, fig.height=3.5, fig.width=4, warning=FALSE}
par(mar = c(4, 4, 1, 0))
set.seed(1234564)
x = abs(rnorm(100,10,10))
y = (x) + 0 + rnorm(length(x), 0, x)
y[29] <- 100
lm=lm(y~scale(x))
plot(lm, which = 5)
```
]
.pull-right[
- Points en dehors de la limite de 0,5 de la distance Cook
- Ces points ont trop d'influence sur la r√©gression
]

.alert[Vous ne devriez jamais supprimer les valeurs aberrantes si vous n'avez pas de bonnes raisons de le faire (ex: erreur de mesure)]

---
# **√âtape 2**. V√©rifier les conditions d'application de `lm1`

```{r, fig.height=5.5, fig.width=7.5}
par(mfrow=c(2,2), mar = c(4,4,2,1.1), oma =c(0,0,0,0))
plot(lm1)
```

---
# conditions d'applications non-respect√©es - quelle est la cause?

Tra√ßons le graphique Y ~ X avec la droite de r√©gression et les histogrammes de Y et X pour explorer leurs distributions

.small[
```{r, fig.height=3, fig.width=10, echo = -1}
par(mfrow=c(1,3), mar = c(4,4,3,1), cex = 0.8)
plot(bird$MaxAbund ~ bird$Mass)
abline(lm1) # adds the best-fit line
hist(bird$MaxAbund) # hist() produces a histogram of the variable
hist(bird$Mass)
```
]

---
# conditions d'applications non-respect√©es - quelle est la cause?

V√©rifions la normalit√© des donn√©es √† l'aide d'un test de `Shapiro-Wilk` et d'un test d'asym√©trie (**`skewness`**) :

```{r}
shapiro.test(bird$MaxAbund)
shapiro.test(bird$Mass)
```
.comment[Dans les deux cas, les distributions ne sont pas normales
]

---
# conditions d'applications non-respect√©es - quelle est la cause?

V√©rifions la normalit√© des donn√©es √† l'aide d'un test de `Shapiro-Wilk` et d'un test d'asym√©trie (**`skewness`**) :

```{r skewness}
library(e1071)
skewness(bird$MaxAbund)
skewness(bird$Mass)
```
.comment[La valeur positive indique que la distribution des donn√©es est d√©cal√©e vers la gauche]

---
# Transformer les donn√©es

- Normalisons les donn√©es en appliquant une transformation `log10()`
- Ajoutons ces variables transform√©es √† notre base de donn√©es

```{r}
bird$logMaxAbund <- log10(bird$MaxAbund)
bird$logMass <- log10(bird$Mass)
```

**√âtape 1**: Ex√©cuter une r√©gression lin√©aire sur les donn√©es transform√©es

```{r}
lm2 <- lm(logMaxAbund ~ logMass, data = bird)
```

---
# **√âtape 2**: V√©rifier les conditions d'applications de `lm2`

```{r, fig.height=5.5, fig.width=7.5}
par(mfrow=c(2,2), mar=c(3,4,1.15,1.2))
plot(lm2)
```

.comment[.center[Beaucoup mieux !]]

---
# **√âtape 2**: V√©rifier les conditions d'applications de `lm2`

```{r, echo=-1, fig.height=4, fig.width=11}
par(mfrow=c(1,3), mar=c(4,4,1.15,1.2))
plot(logMaxAbund ~ logMass, data=bird)
abline(lm2)
hist(log10(bird$MaxAbund))
hist(log10(bird$Mass))
```

---
# **√âtape 3**

**Estimer les param√®tres et leur seuil de signification**

La fonction `summary()` est utilis√©e pour obtenir les param√®tres, leur importance, etc

.small[
```{r}
summary(lm2)
```
]

---
# **√âtape 3**

**Estimer les param√®tres et leur seuil de signification**

Nous pouvons aussi extraire les param√®tres du mod√®le, par exemple :

```{r}
lm2$coefficients
summary(lm2)$coefficients
summary(lm2)$r.squared
```

---
# Discussion de groupe

- Pouvez-vous √©crire l'√©quation de la droite de r√©gression pour votre mod√®le `lm2`
- Les param√®tres sont-ils importants ?
- Quelle proportion de la variance est expliqu√©e par le mod√®le `lm2` ?

.small[
```{r}
summary(lm2)
```
]

---
# Discussion de groupe

Pouvons-nous am√©liorer le mod√®le si nous analysons que les oiseaux terrestres?

.comment[Vous pouvez exclure des objets en utilisant `=!`]

```{r}
lm3 <- lm(logMaxAbund~logMass, data=bird, subset=!bird$Aquatic)
# removes aquatic birds (= TRUE)
# or equivalently
lm3 <- lm(logMaxAbund~logMass, data=bird, subset=bird$Aquatic == 0)
```

```{r eval=FALSE}
# Examine the diagnostic plots
par(mfrow=c(2,2))
plot(lm3)
summary(lm3)

# Compare both models
par(mfrow=c(1,2))
plot(logMaxAbund~logMass, data=bird)
plot(logMaxAbund~logMass, data=bird, subset=!bird$Aquatic)
```

---
# Plot

Sans les oiseaux aquatiques, le `R2-adj` passe de 0.05 √† 0.25 :

```{r, fig.height=4.5, fig.width=9}
par(mfrow=c(1,2), mar = c(4, 4, 3, 1))
plot(logMaxAbund~logMass, data=bird, main = 'Tous les oiseaux')
abline(lm2, col = 'red')
plot(logMaxAbund~logMass, data=bird, subset=!bird$Aquatic, main = 'Oiseaux terrestres')
abline(lm3, col = 'red')
```

---
# D√©fi 1 ![:cube]()

- Examiner la relation entre `log(MaxAbund)` et `log(Mass)` chez les passereaux ("passerine birds")
- Sauvegarder l'objet du mod√®le sous `lm4`

.comment[INDICE: comme les esp√®ces aquatiques, les passereaux sont cod√©es 0/1, ce qui peut √™tre v√©rifi√© √† partir de la structure de la base de donn√©es]

- Comparer la variance expliqu√©e par `lm2`, `lm3` and `lm4`

---
# D√©fi 1 - Solution ![:cube]()

```{r}
# Run the model
lm4 <- lm(logMaxAbund ~ logMass, data = bird, subset=bird$Passerine == 1)
summary(lm4)
```

---
# D√©fi 1 - Solution ![:cube]()

```{r,fig.height=6, fig.width=8}
# diagnostic plots
par(mfrow=c(2,2), mar = c(4,4,2,1.1), oma =c(0,0,0,0))
plot(lm4)
```

---
# D√©fi 1 - Solution ![:cube]()

Comparer la variance expliqu√©e par `lm2`, `lm3` and `lm4`

```{r}
# Recall: we want adj.r.squared
summary(lm2)$adj.r.squared
summary(lm3)$adj.r.squared
summary(lm4)$adj.r.squared
```

.comment[Le meilleur mod√®le parmi les trois est `lm3` *(seulement les oiseaux terrestres)*]

---
# Objectif d'enseignement

.center[
![:scale 100%](images/schema_ttest.png)
]

---
class: inverse, center, middle

# ANOVA

## Test-t
## ANOVA √† un crit√®re de classification
## ANOVA √† deux crit√®res de classification

---
# ANOVA

Variable r√©ponse continue

**Variables explicatives cat√©goriques**

- Deux niveaux ou plus (groupes)

.large[.center[Compare la variation intra-groupe et inter-groupe afin de d√©terminer si les moyennes des groupes diff√®rent]]

---
# ANOVA

.center[Compare la variation intra-groupe et inter-groupe afin de d√©terminer si les moyennes des groupes diff√®rent]

```{r, echo = FALSE, fig.height=3, fig.width=6.5}
source('script/figAnova.R')
```

Somme des carr√©s : variance intra-traitement *vs* variance inter-traitement

Si variance inter traitements $>$ variance intra traitements:
  - la variable explicative a un effet plus important que l'erreur al√©atoire
  - variable explicative est donc susceptible d'influencer significativement la variable r√©ponse

---
# Types d'ANOVA

1. ANOVA √† un crit√®re de classification
  - Une variable explicative cat√©gorique avec au moins 2 niveaux
  - S'il y a 2 niveaux, un **test t** peut √™tre utilis√© alternativement

2. ANOVA √† deux crit√®res de classification
  - Deux variables explicatives cat√©goriques ou plus
  - Chaque facteur peut avoir plusieurs niveaux
  - Les interactions entre chaque facteur doivent √™tre test√©es

--

Mesures r√©p√©t√©es ?
  - L'ANOVA peut √™tre utilis√©e pour des mesures r√©p√©t√©es, mais ce sujet n'est pas abord√© dans cet atelier
  - Mod√®le lin√©aire mixte peut √©galement √™tre utilis√© pour ce type de donn√©es (voir l'atelier 6)

---
class: inverse, center, middle

# Test T

---
# Test T

- **Variable r√©ponse** ![:faic](arrow-right) quantitative
- **Variable explicative** ![:faic](arrow-right) qualitative avec **2 niveaux**

**conditions d'applications**
- Les r√©sidus suivent une distribution normale
- Les variances des groupes sont homog√®nes

.comment[Le test est plus robuste lorsque la taille de l'√©chantillon est plus √©lev√©e et lorsque les groupes ont des tailles √©gales]

---
# Ex√©cuter un test T dans R

Vous pouvez utiliser la fonction `t.test()`

```r
t.test(Y ~ X2, data= data, alternative = "two.sided")
```

  - `Y`: variable r√©ponse
  - `X2`: facteur (2 niveaux)
  - `data`: nom du jeu de donn√©es
  - hypoth√®se `alternative` : `"two.sided"` (par d√©faut), `"less"`, ou `"greater"`

Le test de t est un mod√®le lin√©aire et un cas sp√©cifique de l'ANOVA avec un facteur √† 2 niveaux

Vous pouvez donc aussi utiliser la fonction `lm()`

```r
lm.t < -lm(Y ~ X2, data = data)
anova(lm.t)
```

---
# Ex√©cuter un test T dans R

.large[Les oiseaux aquatiques sont-ils plus lourds que les oiseaux terrestres ?]

- Variable r√©ponse : `Bird mass` ![:faic](arrow-right) num: continue
- Variable explicative : `Aquatic` ![:faic](arrow-right) 2 niveaux : 1 ou 0 (oui ou non)

---
# Ex√©cuter un test T dans R

Premi√®rement, visualiser les donn√©es √† l'aide de la fonction `boxplot()`

```{r eval=TRUE,fig.height=5.2, fig.width=6.5}
boxplot(logMass ~ Aquatic,
        data = bird, names = c("Non aquatique", "Aquatique"))
```

---
# Ex√©cuter un test T dans R

Testons l'homog√©n√©it√© des variances avec la fonction `var.test()`

```{r}
var.test(logMass ~ Aquatic, data = bird)
```

.comment[Le rapport des variances n'est pas statistiquement diff√©rent de 1, celles-ci peuvent donc √™tre consid√©r√©es comme √©gales]

.comment[Nous pouvons maintenant proc√©der au test t !]

---
# Ex√©cuter un test T dans R

```{r}
ttest1 <- t.test(logMass ~ Aquatic, var.equal = TRUE, data = bird)

# Or use lm()
ttest.lm1 <- lm(logMass ~ Aquatic, data=bird)
```

.comment[Sp√©cifie que l'homog√©n√©it√© des variances est respect√©e]

V√©rifiez que `t.test()` et `lm()` donnent le m√™me mod√®le :

```{r}
ttest1$statistic^2
anova(ttest.lm1)$`F value`
# r√©ponse : F=60.3845 dans les deux cas
```

.comment[Lorsque la supposition d'√©galit√© de variance est confirm√©e, t^2 = F]

---
# Ex√©cuter un test T dans R

Si $p<0,01$ (ou $0,05$ ), l'hypoth√®se de l'absence de diff√©rence entre les moyenne des 2 groupes (*H0*) peut √™tre rejet√©e, avec un risque de $0,01$ (ou $0,05$ ) de se tromper

.small[
```{r}
ttest1
```
]

.small[.comment[Il existe une diff√©rence entre la masse des oiseaux aquatiques et terrestres - `p-value`]]

.small[.comment[Regardez les moyennes des 2 groupes]]

---
# Non respect des conditions d'applications

- **Correction de Welch** : lorsque les √©carts entre les groupes ne sont pas √©gaux (par d√©faut dans R !)
- **Test de Mann-Whitney** : l'√©quivalent **non param√©trique** du test de t lorsque les conditions d'applications ne sont pas respect√©es
- **Test de t appari√©** : lorsque les deux groupes ne sont **pas ind√©pendants** (par exemple, des mesures sur la m√™me personne r√©colt√©es lors de 2 ann√©es diff√©rentes)

---
# Discussion de groupe

.large[Les oiseaux aquatiques sont-ils plus lourds que les oiseaux terrestres ?]

```{r}
# Unilateral t-test
uni.ttest1 <- t.test(logMass ~ Aquatic,
                     var.equal = TRUE,
                     data = bird,
                     alternative = "less")
```

.comment[Qu'avez-vous conclu ?]

---
# Discussion de groupe

```{r}
uni.ttest1
```

Oui, les oiseaux aquatiques sont plus lourds que les oiseaux terrestres :

p-value = `r format(uni.ttest1$p.value, scientific=FALSE)`

---
class: inverse, center, middle

# ANOVA

---
# Analyse de Variance (ANOVA)

G√©n√©ralisation du test t √† $>2$ groupes, et/ou ‚â• $2$ facteurs explicatifs

D√©composition de la variance observ√©e de la variable r√©ponse en effets additifs d'un ou de plusieurs facteurs et de leurs interactions

<br>
$$Y = \underbrace{\mu}_{\Large{\text{moyenne globale de la variable r√©ponse}\atop\text{sur tous les individus}}} + \overbrace{\tau_{i}}^{\Large{\text{Le r√©sultat moyen sur}\atop\text{tous les individus du groupe i}}} + \underbrace{\epsilon}_{\text{R√©sidus}}$$

---
# Rappel : ANOVA

conditions d'applications
- Normalit√© des r√©sidus
- L'√©galit√© de la variance inter-groupes

Test compl√©mentaire
- Lorsque l'ANOVA d√©tecte une diff√©rence significative entre les groupes, l'analyse n'indique pas quel(s) groupe(s) diff√®re(nt) de(s) l'autre(s)
- Un test couramment utilis√© a posteriori pour r√©pondre √† cette question est le **Test de Tukey**

---
# Ex√©cuter une ANOVA dans R

##### Est-ce que l'abondance maximale d√©pend du r√©gime alimentaire ?
- Variable r√©ponse : **MaxAbund**  ![:faic](arrow-right) num: quantitative
- Variable explicative : **Diet** ![:faic](arrow-right) facteur avec 5 niveaux

```{r}
str(bird)
```

---
# Visualiser les donn√©es

Visualisons tout d'abord les donn√©es avec la fonction `boxplot()`

```{r, fig.height=5, fig.width=7,echo=-1}
par(mar = c(4, 4, 0.5, 1))
boxplot(logMaxAbund ~ Diet, data = bird,
  ylab = expression("log"[10]*"(Abondance maximale)"), xlab = 'R√©gime alimentaire')
```

---
# Visualiser les donn√©es

Nous pouvons changer l'ordre des niveaux afin qu'il suivent l'ordre croissant de leurs m√©dianes respectives en utilisant les fonctions `tapply()` et `sort()`

```{r, fig.height = 4.5, fig.width = 7, echo = -1}
par(mar = c(4, 4, .1, 1))
med <- sort(tapply(bird$logMaxAbund, bird$Diet, median))
boxplot(logMaxAbund ~ factor(Diet, levels = names(med)), data = bird,
        ylab = expression("log"[10]*"(Abondance maximale)"), xlab = 'R√©gime alimentaire')
```

---
# Visualiser les donn√©es


Une autre fa√ßon de visualiser graphiquement les tailles d‚Äôeffet est d‚Äôutiliser la fonction `plot.design()`

.small[
```{r, fig.height=3.8, fig.width=6, echo=-1}
par(mar = c(4,4,.4,1))
plot.design(logMaxAbund ~ Diet, data = bird,
  ylab = expression("log"[10]*"(Abondance maximale)"))
```
]

.comment[Les niveaux d'un facteur le long d'une ligne verticale, et la valeur globale de la r√©ponse dans une ligne horizontale]

---
# ANOVA √† un crit√®re de classification dans R

Il est de nouveau possible d'utiliser la fonction `lm()`

```{r}
anov1 <- lm(logMaxAbund ~ Diet,
            data = bird)
```

Il y a aussi une fontion sp√©cifique pour l'analyse de la variance dans R `aov()`

```{r}
aov1 <- aov(logMaxAbund ~ Diet,
            data = bird)
```

.comment[Essayez-les et comparez les sorties !]

---
# Ex√©cuter une ANOVA

#### √Ä un crit√®re de classification dans R

Comparer les sorties

```{r}
anova(anov1)
```
```{r}
summary(aov1)
```

---
# V√©rifier les conditions d'application

**Test de Bartlett**: √©galit√© de la variance entre les groupes

.small[
```{r}
bartlett.test(logMaxAbund ~ Diet, data = bird)
```
]
---
# V√©rifier les conditions d'application


**Test de Levene** pour l'homogÈnÈitÈ de la variance:

.small[
```{r}
library(car)
leveneTest(logMaxAbund ~ Diet, data = bird)
```
]

.comment[Le test de Levene performe mieux, mais a une erreur de Type II un peu plus ÈlevÈe.]

---
#V√©rifier les conditions d'application

**Test de Shapiro-Wilk**:  normalit√© des r√©sidus

.small[
```{r}
shapiro.test(resid(anov1))
```
]

.comment[Les deux tests sont non-significatifs; les r√©sidus du mod√®le peuvent √™tre consid√©r√©s normaux et les variances homog√®nes]

---
# Et si les conditions d'applications ne sont pas respect√©es...

**Transformer vos donn√©es** : pourrait √©galiser les variances et normaliser les r√©sidus, et peut convertir un effet multiplicatif en un effet additif

```{r eval=FALSE}
data$logY <- log10(data$Y)
```
* Voir le wiki de l'atelier 1 pour les r√®gles de transformation de donn√©es
* r√©-ex√©cuter votre mod√®le avec la variable transform√©e et v√©rifier √† nouveau les hypoth√®ses

**Test de Kruskal-Wallis**: √©quivalent non param√©trique de l'ANOVA si vous ne pouvez pas
(*ou ne voulez pas*) transformer les donn√©es

```{r eval=FALSE}
kruskal.test(Y~X, data)
```

---
# Sorties de notre mod√®le ANOVA

Triage en ordre alphab√©tique des niveaux et comparaison au niveau de r√©f√©rence (`Insect`)

.small[
```{r}
summary(anov1)
```
]

---
# Sorties de notre mod√®le ANOVA

D'autre part, si nous utilisons `lm()`

.pull-left2[
.small[
```{r}
summary.lm(aov1)
```
]]

.pull-right2[
<br><br>
.comment[Diff√©rence significative entre les groupes, mais nous ne savons pas lesquels !]]

---
# Test a posteriori

Lorsque l'ANOVA d√©tecte un effet significatif de la variable explicative, un test post-hoc avec la fonction `TkeyHSD()`, doit √™tre effectu√© pour d√©terminer quel(s) tratement(s) diff√®re(nt)

.pull-left2[
.small[
```{r}
TukeyHSD(aov(anov1), ordered = TRUE)
```
]]

.pull-right2[
<br><br>
.comment[Seuls `Vertebrate` et `PlantInsect` diff√®rent]
]

---
# Repr√©sentation graphique

Repr√©sentation graphique de l'ANOVA √† l'aide de la fonction `barplot()`

.small[
```{r, fig.height=3.5, fig.width=7,echo=-1}
par(mar=c(3,3,0.5,0.5))
sd <- tapply(bird$logMaxAbund, bird$Diet, sd)
means <- tapply(bird$logMaxAbund, bird$Diet, mean)
n <- length(bird$logMaxAbund)
se <- 1.96*sd/sqrt(n)
bp <- barplot(means, ylim = c(0, max(bird$logMaxAbund) - 0.5))
epsilon = 0.1
segments(bp, means - se, bp, means + se, lwd=2) # barres verticales
segments(bp - epsilon, means - se, bp + epsilon, means - se, lwd = 2) # barres horizontales
segments(bp - epsilon, means + se, bp + epsilon, means + se, lwd = 2) # barres horizontales
```
]

---
class: inverse, center, middle

# ANOVA √† deux crit√®res de classification

---
# ANOVA √† deux crit√®res de classification

Plus d'un facteur

- ANOVA avec un facteur:

 `aov <- lm(Y ~ X, data)`

- ANOVA avec deux ou plus facteurs:

 `aov <- lm(Y ~ X * Z * ..., data)`

.comment[lorsque vous utilisez le symbole "*" avec `lm()`, le mod√®le inclut les effets de chaque facteur s√©par√©ment, ainsi que leur interaction]

.comment[lorsque vous utilisez le symbole "+" avec `lm()`, le mod√®le inclut les effets de
chaque facteur s√©par√©ment (pas d'interaction)]

`aov <- lm(Y ~ X + Z + ..., data)`

---
# ANOVA √† deux crit√®res de classification

.small[

Exemple d'interaction non significative

```r
aov <- lm(Y ~ X * Z, data)
summary(aov)
# Analysis of Variance Table
#
# Response: Y
# Df Sum Sq Mean Sq F value Pr(>F)
# X 4 5.1059 1.27647 3.0378 0.02669 *
# Z 1 0.3183 0.31834 0.7576 0.38870
# X:Z 3 2.8250 0.94167 2.2410 0.10689
# Residuals 45 18.9087 0.42019
# ---
# Signif. codes: 0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1
```

Selon le principe de **parcimonie**, vous voulez que votre mod√®le explique le plus possible de la variance observ√©e dans les donn√©es, avec le moins de termes possible
- Enlever le terme d'interaction s'il n'est pas significatif, et r√©-ex√©cuter le mod√®le

```r
aov <- lm(Y ~ X + Z, data)
```
]

---
# D√©fi 2 ![:cube]()

Testez si l'abondance maximale `log(MaxAbund)` varie √† la fois en fonction du r√©gime alimentaire (`Diet`) et de l'habitat (`Aquatic`)

- .comment[INDICE: Examinez les facteurs Diet, Aquatic et leur interaction avec une ANOVA √† deux crit√®res de classification e.g. `lm(Y ~ A*B)`]

- .comment[o√π A est le premier facteur, B le deuxi√®me et "\*" d√©crit l'interaction]

---
# ![:cube]()

.xsmall[
```{r}
anov2 <- lm(logMaxAbund ~ Diet*Aquatic, data = bird)
summary(anov2)
```
]

---
# D√©fi 2 - Solution ![:cube]()

.xsmall[
```{r}
anov2 <- lm(logMaxAbund ~ Diet*Aquatic, data = bird)
anova(anov2)
```
]

.comment[Le seul terme significatif du mod√®le est le facteur r√©gime alimentaire]

.comment[Selon le principe de parcimonie, nous devrions supprimer le terme d'interaction:]

```r
anov2 <- lm(logMaxAbund ~ Diet, data = bird)
```

---
# Objectif d'enseignement

.center[
![:scale 100%](images/schema_ancova.png)
]

---
class: inverse, center, middle

# ANCOVA

---
# Analyse de covariance (ANCOVA)

- Combinaison de l'ANOVA et de la r√©gression lin√©aire
- Les variables explicatives sont un m√©lange de variables quantitatives (covariable) et qualitatives (facteurs)

$$Y = \mu + \text{Effets principaux des facteurs} + \\
            \text{Interactions entre facteurs} + \\
            \text{Effets principaux des covariables} + \\
            \text{Interactions entre covariables et facteurs} + \epsilon$$

---
# Rappel : ANCOVA

En plus des conditions d'applications des mod√®les lin√©aires, les mod√®les **ANCOVA** doivent respecter :

- Les covariables ont toutes la **m√™me √©tendue de valeurs**
- Les variables sont **fixes**
- Les variables cat√©goriques et continues sont **ind√©pendantes**

<br>

.small[
.comment[Un variable **fixe** est une variable d'int√©r√™t pour une √©tude (e.g. la masse des oiseaux). En comparaison, une variable al√©atoire repr√©sente surtout une source de bruit qu'on veut contr√¥ler (i.e. le site o√π les oiseaux ont √©t√© √©chantillonn√©s)]]

.small[.comment[*Voir l'atelier 6 sur les mod√®les lin√©aires mixtes*]]

---
# Types d'ANCOVA

Vous pouvez avoir n'importe quel nombre de facteurs et / ou variables, mais lorsque leur nombre augmente, l'interpr√©tation des r√©sultats devient de plus en plus complexe

<br>

ANCOVA fr√©quemment utilis√©es

1. **Une covariable et un facteur**
2. Une covariable et deux facteurs
3. Deux covariables et un facteur

.small[.comment[Nous ne consid√©rerons que le premier cas aujourd'hui, mais les deux autres sont similaires]]

---
# ANCOVA avec 1 covariable et 1 facteur

Objectifs de l'analyse :

1. D√©terminer l'effet du facteur et de la covariable sur ‚Äã‚Äãla variable r√©ponse
2. D√©terminer l'effet du facteur sur la variable r√©ponse apr√®s avoir enlev√© l'effet de la covariable
3. D√©terminer l'effet de la covariable sur la variable r√©ponse en contr√¥lant l'effet du facteur

<br>

.center[.alert[Si vous avez une interaction significative entre votre facteur et votre covariable, vous ne pouvez pas atteindre ces objectifs !]]

---
# ANCOVA avec 1 covariable et 1 facteur

<br>

```{r,echo=FALSE,fig.height=3, fig.width=10}
## functions
f1 <- function(x, a, b) {
  return(x*a+b)
}
# conf for plot
col = rgb(118, 143, 175, maxColorValue = 255)
x <- 1:20
par(mfrow = c(1, 3), mar = c(1, 1, 6.5, 4))

# plot 1
plot(x, f1(x, a=1.1,b=2), ylim = c(0, 60), type = 'l', lwd = 2.5, xaxt = "n", yaxt = "n", xlab = "", ylab = "", bty='l', col = col)
lines(f1(x, a=1.1,b=17), lwd = 2.5, col = col)
lines(f1(x, a=0.6,b=22), lwd = 2.5, col = col)
lines(f1(x, a=1.1,b=40), lwd = 2.5, col = col)
mtext('Un niveau du facteur\n a une pente diff√©rente', side = 3, line = 2, cex = 1.5)
# plot 2
plot(x, f1(x, a=.5,b=2), ylim = c(0, 60), type = 'l', lwd = 2.5, xaxt = "n", yaxt = "n", xlab = "", ylab = "", bty='l', col = col)
lines(f1(x, a=1.1,b=17), lwd = 2.5, col = col)
lines(f1(x, a=1.1,b=22), lwd = 2.5, col = col)
lines(f1(x, a=0.01,b=40), lwd = 2.5, col = col)
mtext('Des nombreaux niveaux ont\n des pentes diff√©rentes', side = 3, line = 2, cex = 1.5)
# plot 3
plot(x, f1(x, a=1.1,b=2), ylim = c(0, 60), type = 'l', lwd = 2.5, xaxt = "n", yaxt = "n", xlab = "", ylab = "", bty='l', col = col)
lines(f1(x, a=1.1,b=17), lwd = 2.5, col = col)
lines(f1(x, a=1.1,b=22), lwd = 2.5, col = col)
lines(f1(x, a=1.1,b=40), lwd = 2.5, col = col)
mtext("Pas d'interaction", side = 3, line = 2, cex = 1.5)
```

.pull-left2[.center[.pull-left[![:faic](arrow-up)] .pull-right[![:faic](arrow-up)]]] .pull-right2[.center[![:faic](arrow-up)]]

.center[.pull-left2[.small[Si l'interaction est significative, vous aurez un sc√©nario qui ressemble √† ceci]]]

.pull-right2[.small[Si votre covariable et votre facteur sont significatifs, vous avez un cas comme celui-ci]]

---
# Comparez ANCOVA - moyennes ajust√©es

Si vous voulez comparer les moyennes des diff√©rents facteurs, vous pouvez utiliser les
**moyennes ajust√©es**

La fonction `effect()` utilise les √©quations donn√©es par l'ANCOVA pour estimer les moyennes de chaque niveau, corrig√©es pour l'effet de la covariable

.small[
```{r eval=FALSE, warning=FALSE}
ancova.exemple <- lm(Y ~ X*Z, data=data) # X = quantitative; Z = qualitative
library(effects)
adj.means.ex <- effect('Z', ancova.exemple)
plot(adj.means.ex)
```
]

```{r,echo=FALSE, fig.height=3, fig.width=5}
# plot to simulate effects::effect() plot
a = 40; b =20; sd = 8
par(mar=c(4,4,.5,1))
plot(c(a, b), ylim = c(10, 50), xlim = c(0.9, 2.1), xlab = 'factor Z', ylab = 'Y', xaxt = 'n')
lines(c(a, b), col = 4, pch = 1.5)
segments(c(1, 2), c(a-sd, b-sd), c(1,2), c(a+sd, b+sd), lwd = 1.5, col = 'orange')
segments(c(1, 2) - .04, c(a, b) + sd, c(1, 2) + .04, c(a, b) + sd, lwd = 1.5, col = 'orange')
segments(c(1, 2) - .04, c(a, b) - sd, c(1, 2) + .04, c(a, b) - sd, lwd = 1.5, col = 'orange')
points(c(1, 2), c(a, b), pch = 16, col = 4)
axis(1, at = c(1, 2), labels = FALSE) # add ticks
mtext(c('Level 1', 'Level 2'), 1, at = 1:2, line = 0.5) # add labels to ticks
```

---
# ANCOVA avec 1 covariable et 1 facteur

- Si seulement votre facteur est significatif, √©liminer la covariable -> vous avez une **ANOVA**
- Si seulement votre covariable est significative, √©liminer le facteur -> vous avez une **r√©gression lin√©aire simple**
- Si votre interaction covariable * facteur est significative, vous voudrez peut-√™tre tester quel(s) niveau(x) du facteur a(ont) des pentes diff√©rentes

.alert[V√©rifier vos conditions d'applications ! ]

- Tr√®s similaire √† ce que vous avez fait pr√©c√©demment

---
# Ex√©cuter une ANCOVA dans R

##### L'abondance maximale varie-t-elle en fonction du r√©gime alimentaire et la masse des oiseaux ?

Variable r√©ponse : **MaxAbund** ![:faic](arrow-right) num : quantitative continue

Variable explicatives :
  - **Diet** ![:faic](arrow-right) facteur √† 5 niveaux
  - **Mass** ![:faic](arrow-right) num√©rique continue

.small[
```{r}
str(bird)
```
]

---
# D√©fi 3 ![:cube]()

1- Ex√©cutez un mod√®le pour tester les effets du r√©gime alimentaire (`Diet`), de la masse (`logMass`) ainsi que leur interaction sur l'abondance maximale des oiseaux (`logMaxAbund`)

```{r eval=FALSE}
ancova.exemple <- lm(Y~X*Z, data=data)
summary(ancova.exemple)
```

2- V√©rifiez si votre interaction est significative

```{r eval=FALSE}
ancova.exemple2 <- lm(Y~X+Z, data=data)
summary(ancova.exemple2)
```

---
# D√©fi 3 - Solution ![:cube]()

<br>

```{r}
ancov1 <- lm(logMaxAbund ~ logMass*Diet,
             data = bird)
anova(ancov1)
```

.comment[Interaction entre `logMass` et `Diet` est non-significative]

---
# D√©fi 3 - Solution ![:cube]()

√âliminer le terme d'interaction, puis r√©-√©valuer le mod√®le contenant les effets simples de `logMass` et `Diet`

```{r}
ancov2 <- lm(logMaxAbund ~ logMass + Diet,
             data = bird)
anova(ancov2)
```

---
# Objectif d'enseignement

.center[
![:scale 100%](images/schema_multReg.png)
]

---
class: inverse, center, middle

# R√©gression lin√©aire multiple

---
# R√©gression lin√©aire multiple
- **Variables explicatives** ![:faic](arrow-right) 2 ou plusieurs variables continues
- **Variable r√©ponse** ![:faic](arrow-right) 1 variable continue

Il s'agit d'une g√©n√©ralisation de la r√©gression lin√©aire simple

$$Y_i = \alpha + \beta_1x_{1i}+\beta_2x_{2i}+\beta_3x_{3i}+...+\beta_kx_{ki} + \epsilon$$

conditions d'applications (.small[*En plus des conditions d'applications habituelles des mod√®les lin√©aires*])
- La relation entre chaque variable explicative et la variable r√©ponse est de type lin√©aire
- Les variables explicatives sont orthogonales (pas de colin√©arit√©)

Si colin√©arit√©
1. Gardez seulement **une** des variables colin√©aires
2. Essayez une analyse multidimensionnelle (voir l'atelier 9)
3. Essayez une analyse pseudo-orthogonale

---
#  R√©gression lin√©aire multiple dans R

En utilisant le jeu de donn√©es `Dickcissel` comparez l'importance relative du climat (`clTma`), de la productivit√© (`NDVI`) et de la couverture du sol (`grass`) comme pr√©dicteurs de l'abondance de dickcissels (`abund`)

.small[
```{r, eval=TRUE}
Dickcissel = read.csv("data/dickcissel.csv")
str(Dickcissel)
```
]

---
# V√©rifier les conditions d'applications

La colin√©arit√© :
- V√©rifier la colin√©arit√© de toutes les variables explicatives et d'int√©r√™t

.small[
.pull-left[
```{r, fig.height=6, fig.width=7}
# select variables
var <- c('clTma', 'NDVI', 'grass', 'abund')
plot(Dickcissel[, var])
```
]]

.pull-right[
<br>
.small[.comment[
Si vous observez un patron entre vos deux variables explicatives, elles peuvent √™tre colin√©aires!

Vous devez √©viter ceci, sinon leurs effets sur la variable r√©ponse seront confondus
]]]

---
# R√©gression lin√©aire multiple dans R

Ex√©cuter la r√©gression multiple de l'abondance (`abund`) en fonction des variables `clTma + NDVI + grass`

```{r,eval=FALSE}
lm.mult <- lm(abund ~ clTma + NDVI + grass, data = Dickcissel)
summary(lm.mult)
```

V√©rifiez les autres conditions d'applications, comme pour la r√©gression lin√©aire simple

```{r,eval=FALSE,echo=-2}
par(mfrow = c(2, 2))
par(mfrow=c(2,2), mar = c(3.9,4,1.2,1.1), oma =c(0,0,0,0))
plot(lm.mult)
```

---
# R√©gression lin√©aire multiple dans R

Ex√©cuter la r√©gression multiple de l'abondance (`abund`) en fonction des variables `clTma + NDVI + grass`

.small[
```{r}
lm.mult <- lm(abund ~ clTma + NDVI + grass, data = Dickcissel)
summary(lm.mult)
```
]

---
# R√©gression lin√©aire multiple dans R

V√©rifiez les autres conditions d'applications, comme pour la r√©gression lin√©aire simple

```{r, fig.height=5.5, fig.width=8,echo=-2}
par(mfrow = c(2, 2))
par(mfrow=c(2,2), mar = c(3.9,4,1.2,1.1), oma =c(0,0,0,0))
plot(lm.mult)
```

---
# Quel est le meilleur mod√®le ?
.small[
Souvenez-vous du principe de parcimonie: expliquer le plus de variation avec le plus petit nombre de termes dans votre mod√®le ![:faic](arrow-right) enlevez la variable qui est la moins significative
]

.pull-left2[
.small[
```{r}
summary(lm.mult)
```
]]
.pull-right2[
.small[.comment[
<br>
Les 3 variables sont importantes. On garde tout !

R2-aj: le mod√®le explique 11.28% de la variabilit√© de l'abondance de dickcissels
]]]

---
# Quel est le meilleur mod√®le ?

Il est important de noter que la variable r√©ponse ne varie pas de fa√ßon lin√©aire avec les variables explicatives

```{r, fig.height=3.5, fig.width=11,echo=-1}
par(mfrow=c(1,3), mar=c(4, 4, 0.5, 0.5), cex = 1)
plot(abund ~ clTma, data = Dickcissel)
plot(abund ~ NDVI,  data = Dickcissel)
plot(abund ~ grass, data = Dickcissel)
```

.comment[Voir la **section avanc√©e** sur la **r√©gression polynomiale** pour la solution !]

---
class: inverse, center, middle

# Optionnel

## *si le temps le permet*

---
# Optionnel

1. R√©gression pas √† pas
2. Interpr√©tation des contrastes
3. ANOVA non √©quilibr√©e
4. R√©gression polynomiale
5. Partitionnement de la variation

---
class: inverse, center, middle

# R√©gression pas √† pas

---
# R√©gression pas √† pas

Ex√©cuter un mod√®le avec tout dedans sauf les variables de "Pr√©sent/absence"

La fonction `step()` soustrait un terme au mod√®le de fa√ßon it√©rative et s√©lectionne le meilleur mod√®le
  - c-√†.d. le mod√®le avec le Crit√®re d'Information Akaike (AIC) le plus bas

.small[
```{r,eval=FALSE}
lm.full <- lm(abund ~ . - Present,
              data = Dickcissel)
lm.step <- step(lm.full)
```
]
```{r,include=FALSE}
lm.full <- lm(abund ~ . - Present,
              data = Dickcissel)
lm.step <- step(lm.full)
```

---
# R√©gression pas √† pas

.pull-left[
.tiny[
```{r eval=TRUE}
summary(lm.full)
```
]]

.pull-right[

Variables s√©lection√©es par `step()`
.tiny[
```{r}
summary(lm.step)
```
]]

.small[.comment[Le mod√®le explique maintenant 31,44% de la variabilit√© de l'abondance de Dickcissel]]

---
class: inverse, center, middle

# Interpr√©tation des contrastes

---
# Interpr√©tation des contrastes

.small[
Par d√©faut, `contr.treatment` compare chaque niveau du facteur √† un niveau de r√©f√©rence

L'estimation de l'ordonn√©e √† l'origine est le niveau de r√©f√©rence et correspond √† la moyenne du premier niveau (en ordre alphab√©tique) du facteur `Diet`

Calculez l'ordonn√©e √† l'origine de r√©f√©rence + l'ordonn√©e √† l'origine de chaque niveau de Diet .comment[*Que remarquez-vous ?*]

```{r}
tapply(bird$logMaxAbund, bird$Diet, mean)
coef(anov1)
coef(anov1)[1] + coef(anov1)[2] # InsectVert
coef(anov1)[1] + coef(anov1)[3] # Plant
```
]

---
# Interpr√©tation des contrastes

Il se peut que vous vouliez d√©finir un niveau de r√©f√©rence diff√©rent

1. Comparez le niveau `Plant` √† tous les autres niveaux du facteur `Diet`

```{r,eval=FALSE}
bird$Diet2 <- relevel(bird$Diet, ref="Plant")
anov2 <- lm(logMaxAbund ~ Diet2, data = bird)
summary(anov2)
anova(anov2)
```

2. Ordonner les niveaux selon leur m√©diane

```{r,eval=FALSE}
bird$Diet2 <- factor(bird$Diet, levels=names(med))
anov2 <- lm(logMaxAbund ~ Diet2,
            data = bird)
summary(anov2)
anova(anov2)
```

.comment[Observez-vous un changement quant aux niveaux du facteur `Diet` qui sont significatifs ?]

---
# Interpr√©tation des contrastes

.comment[Un point important √† remarquer √† propos du contraste par d√©faut dans R (`contr.treatment`) est qu'il n'est PAS orthogonal]

Pour √™tre orthogonal :
  - Pour √™tre orthogonal, les propri√©t√©s suivantes doivent √™tre respect√©es:
  - La somme du produit de deux colonnes √©gale 0

```{r}
sum(contrasts(bird$Diet)[,1])
sum(contrasts(bird$Diet)[,1]*contrasts(bird$Diet)[,2])
```

---
# Interpr√©tation des contrastes

Changez les contrastes pour mettre les niveaux orthogonaux

.small[
```{r}
options(contrasts=c("contr.helmert", "contr.poly"))
sum(contrasts(bird$Diet)[,1])
sum(contrasts(bird$Diet)[,1]*contrasts(bird$Diet)[,2])
```
]
.pull-left[
.tiny[
```{r}
anov3 <- lm(logMaxAbund ~ Diet, data = bird)
summary(anov3)
```
]]
.pull-right[
.small[Les contrastes Helmert vont contraster le deuxi√®me niveau avec le premier, le troisi√®me avec la moyenne des deux premiers niveaux, etc.]
]

---
class: inverse, center, middle

# ANOVA non √©quilibr√©e

---
# ANOVA non √©quilibr√©e

Le jeu de donn√©es `Birdsdiet` est en r√©alit√© non √©quilibr√© (le nombre d'esp√®ces aquatiques n'√©gale pas le nombre d'esp√®ces non-aquatiques)

```{r}
table(bird$Aquatic)
```

L'ordre des covariables a chang√© la valeur de la somme des carr√©s

```{r}
unb.anov1 <- lm(logMaxAbund ~ Aquatic + Diet, data = bird)
unb.anov2 <- lm(logMaxAbund ~ Diet + Aquatic, data = bird)
```

---
# ANOVA non √©quilibr√©e

```{r}
anova(unb.anov1)
```

```{r}
anova(unb.anov2)
```

---
# ANOVA non √©quilibr√©e

Maintenant essayez une `Anova()` de type III

.pull-left[
.small[
```{r}
car::Anova(unb.anov1, type = "III")
```
]]
.pull-right[
.small[
```{r}
car::Anova(unb.anov2, type = "III")
```
]]

.comment[Que remarquez-vous en utilisant `Anova()` ?]

---
class: inverse, center, middle

# R√©gression polynomiale

---
# R√©gression polynomiale

Comme nous l'avons remarqu√© dans la section sur la **r√©gression lin√©aire multiple**, certaines variables semblent avoir des relations non-lin√©aires avec la variable `MaxAbund`

Pour tester des relations non-lin√©aires, des r√©gressions polynomiales de diff√©rents degr√©s sont compar√©es

- Un mod√®le polyn√¥mial ressemble √† ceci :

.center[$$\underbrace{2x^4}+\underbrace{3x}-\underbrace{2}$$]

.comment[Ce polyn√¥me a trois termes]

---
# R√©gression polynomiale

Pour un polyn√¥me avec une variable (comme $x$ ), le *degr√©* est l'exposant le plus √©lev√© de cette variable

<br>
.center[*Nous avons ici un polyn√¥me de degr√© 4*]
$$2x^\overbrace{4} + 3x - 2$$

---
# R√©gression polynomiale

Lorsque vous connaissez le degr√©, vous pouvez lui donner un nom :

```{r echo=FALSE, warning=FALSE}

poly.reg=data.frame(degre = 0:5,
                    Nom = c("Constante","Lin√©aire","Quadratique",
                             "Cubique","Quartique","Quintique"),
                    Example = c("\\(3\\)",
                                "\\(x+9\\)",
                                "\\(x^2-x+4\\)",
                                "\\(x^3-x^2+5\\)",
                                "\\(6x^4-x^3+x-2\\)",
                                "\\(x^5-3x^3+x^2+8\\)"))
knitr::kable(poly.reg, format = "html", escape=FALSE)
```

---
# R√©gression polynomiale

En utilisant le jeu de donn√©es `Dickcissel`, testez la relation non-lin√©aire entre l'abondance et la temp√©rature en comparant trois mod√®les polyn√¥miaux group√©s (de degr√©s 0, 1, and 3) :

```{r,echo=-c(4:6)}
lm.linear <- lm(abund ~ clDD, data = Dickcissel)
lm.quad   <- lm(abund ~ clDD + I(clDD^2), data = Dickcissel)
lm.cubic  <- lm(abund ~ clDD + I(clDD^2) + I(clDD^3), data = Dickcissel)
summ_lm.linear <- capture.output(summary(lm.linear))[c(9:12, 17, 18)]
summ_lm.quad <- capture.output(summary(lm.quad))[c(9:13, 18, 19)]
summ_lm.cubic <- capture.output(summary(lm.cubic))[c(9:14, 17, 18)]
```

---
# R√©gression polynomiale

- Comparez les mod√®les polynomiaux et d√©terminez quel mod√®le nich√© nous devrions s√©lectionner
- Ex√©cutez un r√©sum√© de ce mod√®le, reportez l'√©quation de la r√©gression, les valeurs de p, et le R carr√© ajust√©

---
# R√©gression polynomiale

Comparez les mod√®les polyn√¥miaux; .comment[quel mod√®le nich√© nous devrions s√©lectionner ?]

Ex√©cutez un r√©sum√© de ce mod√®le

.tiny[
```{r}
print(summ_lm.linear)
```
```{r}
print(summ_lm.quad)
```
```{r}
print(summ_lm.cubic)
```
]

---
class: inverse, center, middle

# Partitionnement de la variation

---
# Partitionnement de la variation

Certaines variables explicatives de la **r√©gression lin√©aire multiple** √©taient fortement corr√©l√©es (c.-√†-d.
multicolin√©arit√©)

La colin√©arit√© entre variables explicatives peut √™tre d√©tect√©e √† l'aide de crit√®res d'inflation de la variance (fonction `vif()` du packet `car`)
  - Les valeurs sup√©rieures √† 5 sont consid√©r√©es colin√©aires

```{r warning=FALSE,message=FALSE}
mod <- lm(clDD ~ clFD + clTmi + clTma + clP + grass, data = Dickcissel)
car::vif(mod)
```

---
# Partitionnement de la variation
.small[
Utilisez `varpart()` afin de partitionner la variation de la variable `abund` avec toutes les variables de la couverture du paysage group√©es ensemble et toutes les variables du climat group√©es ensemble (laissez NDVI √† part)]

.pull-left2[
.tiny[
```{r warning=FALSE,message=FALSE}
library(vegan)
part.lm = varpart(Dickcissel$abund, Dickcissel[ ,c("clDD","clFD","clTmi","clTma","clP")],
                  Dickcissel[ ,c("broadleaf","conif","grass","crop", "urban","wetland")])
part.lm
```
]]
.pull-right2[
<br><br>
.small[.comment[**Note** : les variables colin√©aires n'ont pas besoin d'√™tre enlev√©es avant l'analyse]]
]

---
# Partitionnement de la variation

.pull-left[
.small[
```{r,fig.height=3.2,echo=-1}
par(mar=rep(0.5,4))
showvarparts(2)
```

```{r,eval=FALSE}
?showvarparts
# With two explanatory tables, the fractions
# explained uniquely by each of the two tables
# are ‚Äò[a]‚Äô and ‚Äò[c]‚Äô, and their joint effect
# is ‚Äò[b]‚Äô following Borcard et al. (1992).
```
]]

.pull-right[
.small[
```{r,fig.height=4,echo=-1}
par(mar=rep(0.5,4))
plot(part.lm,
     digits = 2,
     bg = rgb(48,225,210,80,
              maxColorValue=225),
     col = "turquoise4")
```
]]

.small[.comment[La proportion de la variation de la variable abund expliqu√©e par le climat seulement est 28.5% (obtenu par X1|X2), par la couverture du paysage seulement est ~0% (X2|X1), et par les deux combin√©s est 2.4%]]

---
# Partitionnement de la variation

Tester si chaque fraction est significative

- Climat seul
```{r,eval=FALSE}
out.1 = rda(Dickcissel$abund,
            Dickcissel[ ,c("clDD", "clFD","clTmi","clTma","clP")],
            Dickcissel[ ,c("broadleaf","conif","grass","crop", "urban","wetland")])
```

- Couverture du paysage seul
```{r,eval=FALSE}
out.2 = rda(Dickcissel$abund,
            Dickcissel[ ,c("broadleaf","conif","grass","crop", "urban", "wetland")],
            Dickcissel[ ,c("clDD","clFD","clTmi", "clTma","clP")])

```

```{r,include=FALSE}
out.1 = rda(Dickcissel$abund,
            Dickcissel[ ,c("clDD", "clFD","clTmi","clTma","clP")],
            Dickcissel[ ,c("broadleaf","conif","grass","crop", "urban","wetland")])
out.2 = rda(Dickcissel$abund,
            Dickcissel[ ,c("broadleaf","conif","grass","crop", "urban", "wetland")],
            Dickcissel[ ,c("clDD","clFD","clTmi", "clTma","clP")])
```

---
# Partitionnement de la variation

.pull-left[
.small[
```{r}
# Climat seul
anova(out.1, step = 1000, perm.max = 1000)
```
]]

.pull-right[
.small[
```{r}
# Couverture du paysage seul
anova(out.2, step = 1000, perm.max = 1000)
```
]]

.comment[Conclusion: la fraction expliqu√©e par la couverture du paysage n'est pas significative une fois que nous avons pris en compte l'effet du climat]

---
class: inverse, center, bottom

# Merci d'avoir particip√© !

![:scale 50%](images/qcbs_logo.png)
